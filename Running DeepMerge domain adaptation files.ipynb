{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Running DeepMerge domain adaptation files.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"a_tQaBjysLnj"},"source":["## Training overview:\n","There are 5 different ways you can run training: \n","1. Without Domain Adaptation (noDA) - training only on the source data, but testing on source and target\n","2. With Domain Adaptation (DA) using Maximum Mean Discrepancy (MMD) as transfer loss.\n","3. With Domain Adaptaton using adversarial loss from a DANN as transfer loss (ADA).\n","4. With MMD as transfer loss, with addition of Fisher loss and Entropy minimization loss to make classes more compact and separated (DA+Fisher)\n","5. With adversarial loss and Fisher and Entropy (ADA+Fisher)\n","\n","Additionaly MMD and ADA can be trained with transfer learning by loading pretrained weights of some model.\n","\n","## Files overview:\n","To run the training use the following files from GitHub (galaxy_merge_edits folder):\n","1. For no domain adaptation use: no_domain_adaptation.py\n","2. For MMD (with and without Fisher) use: `train_MMD.py`\n","3. For ADA (with and without Fisher) use:` train_ADA.py`\n","\n","To run evaluation of any of the trained models you use file: evaluation.py\n","\n","Fisher loss and Entropy minimization are removed by adding argument `--fisher_or_no 'no'`. If this argument is not added default value is 'Fisher' and this runs training WITH Fisher loss and Entropy minimizaiton.\n","\n","Transfer learning is added by including `--ckpt_path` argument when running training files. If ommited weights will be randomly initialized.\n","\n","## Data overview:\n","Currently you can run these files for Illustris distant merging galaxies with and without observational noise (Simulation to Simulation) and for Illustris nearby merging galaxies and SDSS observations (Simulation to Real).\n","\n","## Neural Network overview:\n","You can currently run training using:\n","1. ResNet - several sizes from 18 to 152. We are using ResNet18.\n","2. DeepMerge\n","\n","## Outputs:\n","There are many different output files which you get after running training and evaluation:\n","1. `.txt` file looging different losses durin training\n","2. Tensorboard outputs so you can track training or look at losses afterwards\n","3. `best_model.pth.tar` file with weights for best performing model during training.\n","4. Additional folders with optional plots like tSNE, learning rate scan plots (to asses which learning rate to use for one-cycle learning), or Grad-CAMs.\n","5. Running evaluation outputs `.txt` file with confusion matrices and accuracies for classification of images in source and target domain test sets, so you can compare the performance.\n","6. Evaluation also creates two `.csv` files - one with true labels and predictions, and one with output probabilities for both classes.\n","\n","The following cells show how to run training and evaluation and all arguments you need to add in order to run a particular type of experiment."]},{"cell_type":"code","metadata":{"id":"2LWq7BPjaIkv","executionInfo":{"status":"ok","timestamp":1613511277573,"user_tz":360,"elapsed":213,"user":{"displayName":"Aleksandra Ciprijanovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoPcTpgTc3rgP0Kt1m_QyEzKvwMCIs8O188nvi=s64","userId":"09166920093557973472"}}},"source":[" # mount GoogleDrive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5JLFpuMBjsx","executionInfo":{"status":"ok","timestamp":1613511270352,"user_tz":360,"elapsed":228,"user":{"displayName":"Aleksandra Ciprijanovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoPcTpgTc3rgP0Kt1m_QyEzKvwMCIs8O188nvi=s64","userId":"09166920093557973472"}}},"source":["# move to the desired folder on your drive\n","%cd /content/drive/My Drive/Colab Notebooks/FisherDA\n","!ls"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"0IWLWQfKQ3JI"},"source":["import torch\n","import numpy as np\n","from torch.utils.data import Dataset, TensorDataset, DataLoader\n","import torchvision.transforms as transform\n","import matplotlib.pyplot as plt\n","from mlxtend.plotting import plot_confusion_matrix\n","\n","%%capture --no-display\n","!pip3 install tensorboardX\n","!pip3 install tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hkFtnktnS1kz"},"source":["#Function for plotting nice confusion matrices using the output values from txt file we get after evaluation \n","#(numbers have to be added to this function manually at the moment)\n","\n","def plot_confusion_matrix(cm,\n","                          target_names,\n","                          title='Confusion matrix',\n","                          cmap=None,\n","                          normalize=True):\n","    \"\"\"\n","    given a sklearn confusion matrix (cm), make a nice plot\n","\n","    Arguments\n","    ---------\n","    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n","\n","    target_names: given classification classes such as [0, 1, 2]\n","                  the class names, for example: ['high', 'medium', 'low']\n","\n","    title:        the text to display at the top of the matrix\n","\n","    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n","                  see http://matplotlib.org/examples/color/colormaps_reference.html\n","                  plt.get_cmap('jet') or plt.cm.Blues\n","\n","    normalize:    If False, plot the raw numbers\n","                  If True, plot the proportions\n","\n","    Usage\n","    -----\n","    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n","                                                              # sklearn.metrics.confusion_matrix\n","                          normalize    = True,                # show proportions\n","                          target_names = y_labels_vals,       # list of names of the classes\n","                          title        = best_estimator_name) # title of graph\n","\n","    Citiation\n","    ---------\n","    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","\n","    \"\"\"\n","    import matplotlib.pyplot as plt\n","    plt.rcParams.update({'font.size': 24})\n","    import numpy as np\n","    import itertools\n","\n","    accuracy = (np.trace(cm) / float(np.sum(cm)))*100\n","    misclass = 100 - accuracy\n","\n","    if cmap is None:\n","        cmap = plt.get_cmap('Blues')\n","\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","\n","    if target_names is not None:\n","        tick_marks = np.arange(len(target_names))\n","        plt.xticks(tick_marks, target_names, rotation=0)\n","        plt.yticks(tick_marks, target_names)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","\n","    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        if normalize:\n","            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","        else:\n","            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    #plt.xlabel('Predicted label\\naccuracy={:0.2f}; misclass={:0.2f}'.format(accuracy, misclass))\n","    plt.xlabel('\\n Predicted label \\n \\naccuracy={:0.1f}%\\n misclass={:0.1f}%'.format(accuracy,misclass))\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wKmMSiuEw9dV"},"source":["First we have to run tensorboard so it will display progress in real time while we are training (usefull for long runs)"]},{"cell_type":"code","metadata":{"id":"c2_nLV54Ibnd"},"source":["# load tensorboard to look at progress during training\n","\n","%load_ext tensorboard\n","%tensorboard --logdir output_source_target"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v4wPJO_Iig51"},"source":["## Training without domain adaptation - noDA\n"]},{"cell_type":"code","metadata":{"id":"TL6Wn2byi2PT"},"source":["# noDA\n","!python no_domain_adaptation.py --gpu_id 0 \\\n","                              --net DeepMerge \\ # which network to use (we also test ResNet18)\n","                              --dset 'galaxy' \\ # name of our dataset\n","                              --dset_path 'arrays/' \\ #location where the files are\n","                              --output_dir 'output_DeepMerge/' \\ # folder where outputs will be saved\n","                              --source_x_file Xdata_source.npy \\ # names of the source and target image and label files\n","                              --source_y_file ydata_source.npy \\\n","                              --target_x_file Xdata_target.npy \\\n","                              --target_y_file ydata_target.npy \\\n","                              --ly_type cosine \\ # distance calculation method between extracted feature (euclidean or cosine, we use cosine)\n","                              --one_cycle 'yes' \\ # add in case we want leraning rate to change using one-cycle method (defaule value is None, so one-cycle will be omitted)\n","                              --cycle_length 5 \\ # cycle length in epochs\n","                              --lr 0.001 \\ # initial learning rate\n","                              --weight_decay 0.001 \\ # parameter in the optimazier which corresponds to the strenght of L2 regularisation of weights\n","                              --epoch 200 \\ # how many epoch to run\n","                              --early_stop_patience 20 \\ # how many epoch are we willing to tolerate no improvements before we stop\n","                              --optim_choice 'Adam' \\ # optimizer (we use Adam but there is also SGD option)\n","                              --seed 1 \\ # which fixed random seed to use to shuffle images\n","                              --blobs 'yes' \\ # do we want tSNE plots (if this argument is left out default value is None and no tSNEs will be produced)\n","                              --grad_vis 'yes' # do we want to output images to visualize gradients of our network? Only put this option if you want them. Default is no."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lHej_reXlFBr"},"source":["## Training with MMD"]},{"cell_type":"code","metadata":{"id":"NspnKji4lIB0"},"source":["# Train DeepMerge with domain adaptation using MMD (with and without Fisher loss and Entropy minimizaiton)\n","\n","!python train_MMD.py --gpu_id 0 \\\n","                              --net DeepMerge \\\n","                              --dset 'galaxy' \\\n","                              --dset_path 'arrays/' \\\n","                              --output_dir 'output_DeepMerge_SDSS/' \\\n","                              --source_x_file Xdata_source.npy \\ \n","                              --source_y_file ydata_source.npy \\\n","                              --target_x_file Xdata_target.npy \\\n","                              --target_y_file ydata_target.npy \\\n","                              --ly_type cosine \\\n","                              --loss_type mmd \\\n","                              --one_cycle 'yes' \\\n","                              --cycle_length 5 \\\n","                              --lr 0.001 \\\n","                              --epoch 200 \\\n","                              --early_stop_patience 20 \\\n","                              --weight_decay 0.001 \\\n","                              --optim_choice 'Adam' \\\n","                              --seed 1 \\\n","                              --trade_off 1.0 \\ # weight that multiplies transfer loss (MMD) and dictates it's strength\n","                              --fisher_or_no 'Fisher' \\ # Do we want Fisher loss and entropy minimization? Default is 'Fisher', but if we want to remove it we have to add this argument as 'no'\n","                              --em_loss_coef 0.05 \\ # weight that multiplies entropy minimization loss\n","                              --inter_loss_coef 1.0 \\ # weight that multiplies between class matrix of the Fisher loss\n","                              --intra_loss_coef 0.01 \\ # weight that multiplies within class matrix of the Fisher loss\n","                              --blobs 'yes' \\\n","                              --grad_vis 'yes'\\\n","                              --ckpt_path 'output_DeepMerge_SDSS/' # add in case you want to load weights from a pretrained model located in that folder (we used this in case of MMD for Simulated to Real experiment). Default is argument value is None."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YAY0JkkUm1CB"},"source":["## Domain Adversarial training with DANNs - ADA\n","\n"]},{"cell_type":"code","metadata":{"id":"eaYYYcXPm1aP"},"source":["# Train DeepMerge with ADA (with and without Fisher loss and Entropy minimizaiton)\n","\n","!python train_ADA.py --gpu_id 0 \\\n","                              --net DeepMerge \\\n","                              --dset 'galaxy' \\\n","                              --dset_path 'arrays/' \\\n","                              --output_dir 'output_DeepMerge/' \\\n","                              --source_x_file Xdata_source.npy \\ \n","                              --source_y_file ydata_source.npy \\\n","                              --target_x_file Xdata_target.npy \\\n","                              --target_y_file ydata_target.npy \\\n","                              --ly_type cosine \\\n","                              --one_cycle 'yes' \\\n","                              --cycle_length 8 \\\n","                              --lr 0.001 \\\n","                              --epoch 200 \\\n","                              --early_stop_patience 20 \\\n","                              --weight_decay 0.0001 \\\n","                              --seed 1 \\\n","                              --optim_choice 'Adam' \\\n","                              --trade_off 1.0 \\\n","                              --fisher_or_no 'Fisher' \\\n","                              --em_loss_coef 0.05 \\ \n","                              --inter_loss_coef 1.0 \\ \n","                              --intra_loss_coef 0.01 \\\n","                              --blobs 'yes' \\\n","                              --grad_vis 'yes' \\\n","                              --ckpt_path 'output_DeepMerge_SDSS/' # add in case you want to load weights from a pretrained model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AK-rgAMCqpMK"},"source":["# Note:\n","\n","In case you want to run **with transfer learning** from a pretrained model you have to manually add fixed mean and std values for normalizartion (for images that the pretrained model was trained on). This is done in `import_and_nomralize.py`. Example that we used can be found commented out in the given file."]},{"cell_type":"markdown","metadata":{"id":"52JvWSfsoFkI"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"hJs1bepMkuhv"},"source":["# Evaluation of all experiments\n","\n","!python evaluation.py --gpu_id 0 \\\n","                --net DeepMerge \\\n","                --dset 'galaxy' \\\n","                --dset_path 'arrays' \\\n","                --ly_type cosine \\\n","                --ckpt_path 'output_DeepMerge' \\ # where to load the trained model from\n","                --source_x_file Xdata_source.npy \\ \n","                --source_y_file ydata_source.npy \\\n","                --target_x_file Xdata_target.npy \\\n","                --target_y_file ydata_target.npy \\\n","                --seed 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M2qjfsXwodQ1"},"source":["Plotting nice Confusion Matrices"]},{"cell_type":"code","metadata":{"id":"JrFCILfYlK22"},"source":["# Numbers in the matrix ahve to be added manually after you run evaluation\n","\n","plot_confusion_matrix(cm           = np.array([[567, 52],\n","                                               [47, 534]]), \n","                      normalize    = True,\n","                      target_names = ['Non-Merger', 'Merger'],\n","                      title        = \"SOURCE noDA\")\n","\n","plot_confusion_matrix(cm           = np.array([[111, 479],\n","                                               [125, 485]]), \n","                      normalize    = True,\n","                      target_names = ['Non-Merger', 'Merger'],\n","                      title        = \"TARGET noDA\")"],"execution_count":null,"outputs":[]}]}